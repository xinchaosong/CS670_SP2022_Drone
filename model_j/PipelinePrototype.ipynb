{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"v-Dmebs0rAd8"},"outputs":[],"source":["#Set Up Modules:\n","#--------------------------------------------------------------------------------------\n","import numpy as np                 #library for working with arrays\n","import matplotlib.pyplot as plt    #libary for plotting (extension of numpy)\n","import re as regex                 #library for regular expressions\n","import cv2                         #libary to solve computer vision problems\n","import math                        #math tools\n","import random                      #library for randomization tools\n","import time                        #library for timing tools\n","import statistics as stat\n","import pickle\n","\n","import winsound\n","import os, sys\n","from os import listdir, makedirs   #to use \"listdir\" and \"mkdir\"\n","from os.path import isfile, join, exists   #to use file tools\n","import copy\n","\n","# from easy_table import EasyTable\n","import keras\n","from keras.models import model_from_json\n","from keras.backend import manual_variable_initialization \n","manual_variable_initialization(True)\n","from PIL import Image\n","\n","\n","#Functions I wrote:\n","#-------------------------------------------------------------------\n","import CustomAssertions\n","import Distance\n","import Imaging\n","from Imaging import FrameManager, Background, CustomImage\n","import FeatureTools\n","import HandAssessments\n","from Analysis import StopWatch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2l0kh_2rAeA"},"outputs":[],"source":["### SETUP ENVIRONMENT ###\n","#---search paths\n","rootFolder = r\"C:\\Users\\james\\Desktop\\Work_Spaces\\00-School\\02-Graduate\\07-AdvTopicDeepLearning\\00-Drone_Project\"\n","dataSubFolder = r\"04-Data2\\01-RawImages_All\"\n","modelSubFolder = r\"06-Models\\00-Model_1\"\n","# modelName = 'MODEL_1_RGB_Apr5_2022'\n","modelName = 'MODEL_1_Apr4_2022'\n","ResultsSubfolder = r\"04-Data2\\03-AdditionalBackground_100x100\\01-Grayscale\"\n","fileSearchRE = \"[0-9]_Feet_[0-9_]+.jpg\"\n","\n","#---options\n","imgShrinkFactor = 0.30     #% (fraction) of current size (keep aspect ratio)\n","finalImageSize = (100,100) #% ((pixels,pixels)) size of training sample image\n","singleStrat = True\n","distance = [2,3,4]\n","color = \"Grayscale\"\n","\n","#---load json strings into memory\n","json_file_gestures = open(rootFolder + '/' + modelSubFolder + '/' + modelName + '.json', 'r')\n","loaded_model_json_gestures = json_file_gestures.read()\n","json_file_gestures.close()\n","Model_1   = model_from_json(loaded_model_json_gestures)\n","\n","#---load weights into new model\n","Model_1.load_weights(rootFolder + '/' + modelSubFolder + '/' + modelName + \".h5\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RoXVv2ycrAeB"},"outputs":[],"source":["def WriteImageToFile(pathToImageFolder, imageName, img):\n","    pathToImage = pathToImageFolder + '\\\\' + imageName + \".jpg\"\n","    cv2.imwrite(pathToImage, img)\n","\n","    \n","def eliminateInnerBoxes(boxes):\n","    boxes.sort(key=lambda x: ((x[0]+x[2]) * (x[1]+x[3])), reverse=True)\n","    print(\"sorted boxes: \", boxes)\n","    #cycle through boxes, pop boxes from list when they are found to be duplicates of the reference one.\n","    endPoint = len(boxes)-1 \n","    i = 0\n","    while i < endPoint:\n","        #for all other elements, left to right, calculate IOU\n","        copies = [j for j in range(i+1,endPoint+1) if isBoxInsideBox(boxes[j],boxes[i])]\n","\n","        #remove all copies from list\n","        boxes = [val for index,val in enumerate(boxes) if index not in copies]\n","\n","        #update item in list to use next\n","        endPoint -= len(copies)\n","        i += 1        \n","    return boxes\n","    \n","def isBoxInsideBox(box1,box2):\n","    return box1[0] >= box2[0] and box1[1] >= box2[1] and box1[0]+box1[2] <= box2[0]+box2[2] and box1[1]+box1[3] <= box2[1]+box2[3]\n","\n","\n","\n","\n","    \n","def NonMaximumSuppression(boxes, confidences, IOU_Allowance=0.40):\n","    boxConfidence = list(zip(boxes, confidences))\n","    boxConfidence.sort(key=lambda x: x[1], reverse=True)\n","    \n","    #cycle through boxes, pop boxes from list when they are found to be duplicates of the reference one.\n","    endPoint = len(boxConfidence)-1 \n","    i = 0\n","    while i < endPoint:\n","        #for all other elements, left to right, calculate IOU\n","        copies = [j for j in range(i+1,endPoint+1) if IOU(boxConfidence[i][0], boxConfidence[j][0]) > IOU_Allowance]\n","\n","        #remove all copies from list\n","        boxConfidence = [val for index,val in enumerate(boxConfidence) if index not in copies]\n","\n","        #update item in list to use next\n","        endPoint -= len(copies)\n","        i += 1      \n","    \n","    boxes = []\n","    for item in boxConfidence:\n","        boxes.append(item[0])\n","    return boxes\n","\n","\n","def IOU(a, b, epsilon=1e-5):\n","    \"\"\"\n","        Intersection over union to identify the most unique region proposals so that there are not duplicate images.\n","    \"\"\"\n","    #coordinates of intersection box\n","    x1 = max(a[0], b[0])\n","    y1 = max(a[1], b[1])\n","    x2 = min(a[0] + a[2], b[0] + b[2])\n","    y2 = min(a[1] + a[3], b[1] + b[3])\n","\n","    #area where the boxes intersect\n","    area_overlap = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n","\n","    #combined area\n","    area_a = (a[2] + 1) * (a[3] + 1)\n","    area_b = (b[2] + 1) * (b[3] + 1)\n","    area_combined = area_a + area_b - area_overlap\n","    return abs(area_overlap / (area_combined+epsilon))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQ31JH39rAeC","outputId":"40745a20-acbf-4ff4-8777-6695b878e3e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of images found -->  633\n","----> Frame:  2_Feet_1.jpg\n","---->BOXES FOUND: 79\n","sorted boxes:  [[0, 0, 262, 59]]\n","----> Frame:  2_Feet_10.jpg\n","---->BOXES FOUND: 95\n","sorted boxes:  [[7, 0, 281, 216], [174, 158, 51, 58], [206, 113, 24, 45], [206, 39, 34, 38]]\n","----> Frame:  2_Feet_100.jpg\n","---->BOXES FOUND: 168\n","sorted boxes:  [[51, 35, 148, 181]]\n","----> Frame:  2_Feet_101.jpg\n","---->BOXES FOUND: 160\n","sorted boxes:  [[48, 34, 149, 182], [67, 162, 35, 54]]\n","----> Frame:  2_Feet_102.jpg\n","---->BOXES FOUND: 198\n","sorted boxes:  [[43, 55, 151, 161], [57, 179, 62, 37], [53, 144, 48, 38], [74, 55, 50, 31]]\n","----> Frame:  2_Feet_103.jpg\n","---->BOXES FOUND: 178\n","sorted boxes:  [[61, 50, 128, 166], [87, 0, 35, 82]]\n","----> Frame:  2_Feet_104.jpg\n","---->BOXES FOUND: 165\n","sorted boxes:  [[0, 82, 168, 134], [147, 107, 19, 46], [67, 82, 44, 47]]\n","----> Frame:  2_Feet_105.jpg\n","---->BOXES FOUND: 181\n","sorted boxes:  [[0, 98, 167, 118], [106, 48, 20, 41]]\n","----> Frame:  2_Feet_106.jpg\n","---->BOXES FOUND: 185\n","sorted boxes:  [[72, 65, 134, 151]]\n","----> Frame:  2_Feet_107.jpg\n","---->BOXES FOUND: 199\n","sorted boxes:  [[109, 66, 118, 126]]\n","----> Frame:  2_Feet_108.jpg\n","---->BOXES FOUND: 184\n","sorted boxes:  [[112, 71, 116, 145], [168, 0, 38, 109], [70, 129, 43, 10], [59, 67, 71, 31]]\n","----> Frame:  2_Feet_109.jpg\n","---->BOXES FOUND: 195\n","sorted boxes:  [[101, 114, 62, 102]]\n","----> Frame:  2_Feet_11.jpg\n","---->BOXES FOUND: 136\n","sorted boxes:  [[0, 0, 288, 216], [178, 148, 52, 68], [215, 95, 20, 54], [187, 57, 65, 33], [38, 67, 36, 149], [121, 0, 167, 35]]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-85-bacfeb074a35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthisTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;31m#         print(\"AFTER: \", reducedBoxes)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mImaging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthisTest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Desktop\\Work_Spaces\\00-School\\02-Graduate\\07-AdvTopicDeepLearning\\00-Drone_Project\\05-Scripts\\Imaging.py\u001b[0m in \u001b[0;36mshowImage\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m    446\u001b[0m     \"\"\"\n\u001b[0;32m    447\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test image\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m     \u001b[1;31m#cv2.destroyAllWindows()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#Prepare background images\n","#----------------------------------------------------------------------------------------------------------------\n","    \n","#--------------------------------------------- AUTOMATION SECTION --------------------------------------------------\n","#color to image shape\n","if color == \"RGB\":\n","    imageLayers = 3\n","else:\n","    imageLayers = 1\n","\n","#initialize overall timing stuff\n","SelectiveSearchModel = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n","\n","#initialize overall timing stuff\n","for dist in distance:\n","    #grab new frame manager\n","    frameManager = FrameManager(\"%d_Feet\" % dist, rootFolder, dataSubFolder, ResultsSubfolder, fileRegEx=fileSearchRE, COLOR=\"RGB\")\n","    if frameManager._managerStatus is -1:\n","        continue\n","\n","    #run algorithm for one set of images \n","    while(frameManager.imagesOnStack >=1): \n","        #update counters for image labeling\n","        frameManager.setNextFrame()                             #get next frame on stack\n","        c_Frame = frameManager.getCurrentFrame()                #snag current frame\n","        print(\"----> Frame: \", frameManager.currentImageName)   #print name of frame\n","        img = c_Frame.image\n","        imgSize = np.shape(img)                       #capture image size (different sizes depending on cropping)\n","        img = cv2.resize(img, (int(imgShrinkFactor*imgSize[1]), int(imgShrinkFactor*imgSize[0])), interpolation=cv2.INTER_LANCZOS4)\n","\n","        SelectiveSearchModel.setBaseImage(img)\n","        SelectiveSearchModel.switchToSelectiveSearchFast()\n","        if singleStrat == True: \n","            SelectiveSearchModel.switchToSingleStrategy()   \n","        rects = SelectiveSearchModel.process()\n","        print(\"---->BOXES FOUND:\", len(rects))\n","\n","        #show sample images\n","        if color == 'Grayscale':\n","            test = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY)\n","        else:\n","            test = img.copy()\n","        listOfBoxBoxes = []\n","        predictionArray = []\n","        for (x, y, w, h) in rects:\n","            thisTest = test.copy()\n","            snippetSize = np.shape(test[y:y+h, x:x+w])\n","            if snippetSize[0]*snippetSize[1] > 0:\n","                rs_test = cv2.resize(test[y:y+h, x:x+w], finalImageSize, interpolation=cv2.INTER_LANCZOS4)\n","                rs_test = rs_test.astype('float32')\n","                rs_test /=  255.0\n","                prediction = Model_1(np.reshape(rs_test,(-1,100,100,imageLayers)), training=False).numpy()\n","                predictedClass = \"BOX\" if prediction[0][1] > 0.85 else \"NOTBOX\"\n","                if predictedClass == \"BOX\":\n","                    listOfBoxBoxes.append([x, y, w, h])\n","                    predictionArray.append(prediction[0][1])\n","        \n","#         for (x, y, w, h) in listOfBoxBoxes:\n","#             cv2.putText(thisTest, \"[BOX]\", (x,y+h), cv2.FONT_HERSHEY_SIMPLEX, 0.4, 255)\n","#             cv2.rectangle(thisTest, (x, y), (x + w, y + h), [90,90,90], 2)\n","#         print(\"BEFORE: \", listOfBoxBoxes)\n","#         Imaging.showImage(thisTest)\n","        \n","        nonDuplicates = NonMaximumSuppression(listOfBoxBoxes, predictionArray, IOU_Allowance=0.10)\n","        removedInnerBoxes = eliminateInnerBoxes(nonDuplicates)\n","        thisTest = test.copy()\n","        for (x, y, w, h) in removedInnerBoxes:\n","            cv2.putText(thisTest, \"[BOX]\", (x,y+h), cv2.FONT_HERSHEY_SIMPLEX, 0.4, 255)\n","            cv2.rectangle(thisTest, (x, y), (x + w, y + h), [90,90,90], 2)\n","#         print(\"AFTER: \", reducedBoxes)\n","        Imaging.showImage(thisTest)        \n","        \n","        \n","\n","                \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RFYK-larAeD"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o4ElL9PVrAeE","outputId":"462fb12f-9438-4310-9ab9-c44c2d410e24"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.599999760000096\n","0.12396693190355934\n","[0.483333327962963, 0.966666655925926]\n","[[0, 132, 149, 5]]\n"]}],"source":["print(IOU([0,0,2,4], [0,0,4,4]))\n","print(IOU([0,0,10,10], [0,0,2,4]))\n","print(NonMaximumSuppression([[0, 132, 144, 2], [0, 132, 149, 5], [0, 132, 144, 5]], predictionArray))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KoEsA5enrAeE","outputId":"86296f64-441d-42be-fb70-8bbfc6565719"},"outputs":[{"name":"stdout","output_type":"stream","text":["[([14, 69, 84, 102], 0.999813), ([14, 67, 68, 101], 0.98575634)]\n","boxConfidence_1: ([14, 69, 84, 102], 0.999813)\n","boxConfidence_1: ([14, 67, 68, 101], 0.98575634)\n","[0.7758911494704924]\n","[[14, 69, 84, 102], [14, 67, 68, 101]]\n","0.7758911494704924\n"]}],"source":["def NonMaximumSuppression(boxes, confidences, IOU_Allowance=0.40):\n","    boxConfidence = list(zip(boxes, confidences))\n","    boxConfidence.sort(key=lambda x: x[1], reverse=True)\n","    print(boxConfidence)\n","    \n","    #cycle through boxes, pop boxes from list when they are found to be duplicates of the reference one.\n","    endPoint = len(boxConfidence)-1 \n","    i = 0\n","    while i < endPoint:\n","        print(\"boxConfidence_1:\", boxConfidence[0])\n","        print(\"boxConfidence_1:\", boxConfidence[1])\n","        #for all other elements, left to right, calculate IOU\n","        copies = [j for j in range(i+1,endPoint+1) if IOU(boxConfidence[i][0], boxConfidence[j][0]) > IOU_Allowance]\n","        print([IOU(boxConfidence[i][0], boxConfidence[j][0]) for j in range(i+1,endPoint+1)])\n","        #remove all copies from list\n","        boxConfidence = [val for index,val in enumerate(boxConfidence) if index not in copies]\n","\n","        #update item in list to use next\n","        endPoint -= len(copies)\n","        i += 1      \n","    return boxes    \n","    \n","    \n","confidence = predictionArray\n","boxes = listOfBoxBoxes\n","print(NonMaximumSuppression([[0, 132, 144, 2], [0, 132, 149, 5], [0, 132, 144, 5]], confidence))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"39TwTpSOrAeF","outputId":"213fb19e-d758-4fa1-a30a-dc7c159afdcf"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","sorted boxes:  [[0, 0, 10, 10], [1, 1, 6, 6], [1, 1, 2, 2]]\n","[[0, 0, 10, 10]]\n"]}],"source":["def eliminateInnerBoxes(boxes):\n","    boxes.sort(key=lambda x: ((x[0]+x[2]) * (x[1]+x[3])), reverse=True)\n","    print(\"sorted boxes: \", boxes)\n","    #cycle through boxes, pop boxes from list when they are found to be duplicates of the reference one.\n","    endPoint = len(boxes)-1 \n","    i = 0\n","    while i < endPoint:\n","        #for all other elements, left to right, calculate IOU\n","        copies = [j for j in range(i+1,endPoint+1) if isBoxInsideBox(boxes[j],boxes[i])]\n","\n","        #remove all copies from list\n","        boxes = [val for index,val in enumerate(boxes) if index not in copies]\n","\n","        #update item in list to use next\n","        endPoint -= len(copies)\n","        i += 1        \n","    return boxes\n","    \n","def isBoxInsideBox(box1,box2):\n","    return box1[0] >= box2[0] and box1[1] >= box2[1] and box1[0]+box1[2] <= box2[0]+box2[2] and box1[1]+box1[3] <= box2[1]+box2[3]\n","\n","    \n","    \n","    \n","boxList = [ [0,0,10,10],\n","            [1,1,2,2],\n","            [1,1,6,6]]\n","print(isBoxInsideBox(boxList[1],boxList[2]))\n","print(eliminateInnerBoxes(boxList))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J_G-yxgYrAeF"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jaof2toTrAeG"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5u_fDpasrAeG"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_oMnrrFOrAeG"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"PipelinePrototype.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}